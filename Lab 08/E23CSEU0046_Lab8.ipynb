import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from collections import Counter

# Step 1: Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target
class_names = iris.target_names

# Step 2: Initialize the Decision Tree Classifier
clf = DecisionTreeClassifier(random_state=42)

# Step 3: Set up 5-fold cross-validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# To store metrics
accuracies, precisions, recalls, f1_scores = [], [], [], []

# Step 4: Loop through each fold
fold = 1
for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    # Train the classifier
    clf.fit(X_train, y_train)

    # Predict
    y_pred = clf.predict(X_test)

    # Compute metrics
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)
    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)

    # Append metrics
    accuracies.append(acc)
    precisions.append(prec)
    recalls.append(rec)
    f1_scores.append(f1)

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    # Step 6: Plot confusion matrix
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Confusion Matrix - Fold {fold}')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

    # Step 8: Class distribution in test fold
    label_counts = Counter(y_test)
    plt.figure()
    plt.bar(label_counts.keys(), label_counts.values(), tick_label=class_names)
    plt.title(f'Class Distribution in Test Set - Fold {fold}')
    plt.xlabel('Class')
    plt.ylabel('Count')
    plt.show()

    print(f"Fold {fold} - Accuracy: {acc:.2f}, Precision: {prec:.2f}, Recall: {rec:.2f}, F1 Score: {f1:.2f}\n")
    fold += 1

print("=== Average Performance Across 5 Folds ===")
print(f"Average Accuracy: {np.mean(accuracies):.2f}")
print(f"Average Precision: {np.mean(precisions):.2f}")
print(f"Average Recall: {np.mean(recalls):.2f}")
print(f"Average F1 Score: {np.mean(f1_scores):.2f}")
